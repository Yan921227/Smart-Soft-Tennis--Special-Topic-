import cv2
import os
from pathlib import Path

def overlay_annotation(image, annotation_path):
    """
    è®€å–æ¨™è¨»æª”ï¼Œå°‡ YOLOv8-Pose æ ¼å¼æ¨™è¨»ç–ŠåŠ åˆ°åœ–ç‰‡ä¸Š
    æ¨™è¨»æ ¼å¼ï¼ˆå–®è¡Œï¼‰ï¼š
    <class_id> <bbox_center_x> <bbox_center_y> <bbox_width> <bbox_height>
    <kpt0_x> <kpt0_y> <kpt0_visibility> ... <kptN_x> <kptN_y> <kptN_visibility>
    (æ‰€æœ‰æ•¸å€¼çš†ç‚º normalized å€¼ï¼Œ0 ~ 1)
    """
    img_h, img_w, _ = image.shape

    with open(annotation_path, "r", encoding="utf-8") as f:
        lines = f.readlines()

    for line in lines:
        line = line.strip()
        if not line:
            continue
        # è½‰æ›æˆæ•¸å€¼åˆ—è¡¨
        values = list(map(float, line.split()))
        if len(values) < 5:
            print("æ¨™è¨»è³‡æ–™ä¸è¶³ï¼š", annotation_path)
            continue

        # è§£æå‰ 5 å€‹æ•¸å€¼ï¼šclass_id, bbox_center_x, bbox_center_y, bbox_width, bbox_height
        class_id = int(values[0])
        bbox_cx = values[1]
        bbox_cy = values[2]
        bbox_w = values[3]
        bbox_h = values[4]

        # æ ¹æ“š normalized å€¼è¨ˆç®— bounding box å·¦ä¸Šè§’èˆ‡å¯¬é«˜
        x_min = int((bbox_cx - bbox_w / 2) * img_w)
        y_min = int((bbox_cy - bbox_h / 2) * img_h)
        box_w = int(bbox_w * img_w)
        box_h = int(bbox_h * img_h)

        # ç•«å‡º bounding box èˆ‡é¡åˆ¥æ¨™ç±¤
        cv2.rectangle(image, (x_min, y_min), (x_min + box_w, y_min + box_h), (0, 255, 0), 2)
        cv2.putText(image, f"ID:{class_id}", (x_min, y_min - 5),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

        # å¾ŒçºŒæ¯ 3 å€‹æ•¸å€¼ç‚ºä¸€çµ„ï¼šé—œéµé»çš„ (x, y, visibility)
        keypoints = values[5:]
        num_kpts = len(keypoints) // 3
        for i in range(num_kpts):
            kp_x = keypoints[i * 3]
            kp_y = keypoints[i * 3 + 1]
            kp_v = keypoints[i * 3 + 2]
            # è½‰æ›æˆåœ–ç‰‡çš„åƒç´ åº§æ¨™
            pt_x = int(kp_x * img_w)
            pt_y = int(kp_y * img_h)
            # æ ¹æ“šå¯è¦‹åº¦æ±ºå®šé¡è‰²ï¼ˆå¯è¦‹åº¦é«˜ç”¨ç´…è‰²ï¼Œå¦å‰‡è—è‰²ï¼‰
            color = (0, 0, 255) if kp_v > 0.5 else (255, 0, 0)
            cv2.circle(image, (pt_x, pt_y), 3, color, -1)
            cv2.putText(image, str(i), (pt_x, pt_y),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.3, color, 1)
    return image

def process_folder(image_folder, annotation_folder, output_folder):
    """
    éæ­·åœ–ç‰‡è³‡æ–™å¤¾ï¼Œå°æ¯å¼µåœ–ç‰‡è®€å–å°æ‡‰çš„æ¨™è¨»æª”ï¼ˆä»¥åœ–ç‰‡åŒåä½†å‰¯æª”åç‚º .txtï¼‰
    ä¸¦å°‡ç–ŠåŠ æ¨™è¨»å¾Œçš„åœ–ç‰‡å­˜åˆ°è¼¸å‡ºè³‡æ–™å¤¾ã€‚
    """
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    image_files = [f for f in os.listdir(image_folder)
                   if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

    for filename in image_files:
        image_path = os.path.join(image_folder, filename)
        annotation_filename = os.path.splitext(filename)[0] + ".txt"
        annotation_path = os.path.join(annotation_folder, annotation_filename)

        if not os.path.exists(annotation_path):
            print(f"æ‰¾ä¸åˆ° {filename} å°æ‡‰çš„æ¨™è¨»æª”ï¼š{annotation_filename}")
            continue

        image = cv2.imread(image_path)
        if image is None:
            print("ç„¡æ³•è®€å–åœ–ç‰‡:", image_path)
            continue

        annotated_image = overlay_annotation(image, annotation_path)

        # å„²å­˜ç–ŠåŠ å¾Œçš„åœ–ç‰‡ï¼Œä¸é¡¯ç¤ºè¦–çª—
        output_path = os.path.join(output_folder, filename)
        cv2.imwrite(output_path, annotated_image)
        print(f"âœ… å·²å„²å­˜ç–ŠåŠ æ¨™è¨»åœ–ç‰‡ï¼š{output_path}")

if __name__ == "__main__":
    # åœ–ç‰‡è³‡æ–™å¤¾èˆ‡æ¨™è¨»è³‡æ–™å¤¾ï¼ˆä½ åŸæœ¬æŒ‡å®šçš„çµ•å°è·¯å¾‘ï¼‰
    image_folder = "C:\\Users\\User\\Desktop\\picture\\IMG_8203"
    annotation_folder = "C:\\Users\\User\\Desktop\\YOLO TXT\\IMG_8203"

    # ğŸ‘‰ ä¿®æ”¹å¾Œï¼šå°‡ç–ŠåŠ åœ–ç‰‡è¼¸å‡ºåˆ° py æª”æ‰€åœ¨ä½ç½®ä¸‹çš„ output_overlay/IMG_8203
    output_folder = Path.cwd() / "YOLO_txt_output_overlay" / "IMG_8203"

    process_folder(image_folder, annotation_folder, str(output_folder))
